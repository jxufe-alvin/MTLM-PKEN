{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldx/anaconda3/envs/xc/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.tokenization_roberta import RobertaTokenizer\n",
    "\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_mental_health(Dataset):\n",
    "    def __init__(self, data_path, add_title=True):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.posts = self.data.post.values.tolist()  # type: ignore\n",
    "        if add_title:\n",
    "            self.data['title_post'] = self.data.apply(lambda x: x['title'] + x['post'], axis=1)\n",
    "            self.posts = self.data.title_post.values.tolist()  # type: ignore\n",
    "        else:\n",
    "            self.posts = self.data.post.values.tolist()\n",
    "        self.labels = self.data.class_id.values.tolist()  # type: ignore\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        post = self.posts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return post, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_dataloader_mental_health(train_path, tokenizer, batch_size, pad_size, device, add_title):\n",
    "    \"\"\"构建一个数据集迭代器，\n",
    "\n",
    "    Args:\n",
    "        config (class): 配置参数的实例\n",
    "    \"\"\"\n",
    "\n",
    "    def collate_fn(data):\n",
    "        \"\"\"怎么取数据\n",
    "\n",
    "        Args:\n",
    "            data (dataset): 上面构建的数据集\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        posts = [i[0] for i in data]\n",
    "        labels = [i[1] for i in data]\n",
    "\n",
    "        #编码\n",
    "        inputs = tokenizer.batch_encode_plus(batch_text_or_text_pairs=posts,\n",
    "                                    truncation=True,\n",
    "                                    padding='max_length',\n",
    "                                    max_length=pad_size,   #   修改过\n",
    "                                    return_tensors='pt')\n",
    "                                    # return_length=True)\n",
    "\n",
    "        for  i in inputs:\n",
    "            inputs[i] = inputs[i].to(device)\n",
    "\n",
    "        labels = torch.LongTensor(labels).to(device)\n",
    "        #input_ids:编码之后的数字\n",
    "        #attention_mask:是补零的位置是0,其他位置是1\n",
    "        # input_ids = data['input_ids'].to(device)\n",
    "        # attention_mask = data['attention_mask'].to(device)\n",
    "        # if model_name == 'bert-base-uncased':\n",
    "        #     token_type_ids = data['token_type_ids'].to(device)\n",
    "\n",
    "        return (inputs, labels, posts)\n",
    "\n",
    "    dataset_train = multi_mental_health(train_path, add_title)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=dataset_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    collate_fn=collate_fn,\n",
    "                                    shuffle=True,\n",
    "                                    drop_last=True)\n",
    "\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_path = 'roberta地址'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(roberta_path)\n",
    "loader_embed = building_dataloader_mental_health(train_path='./train_self_harm.csv', \n",
    "                                                    tokenizer=tokenizer, \n",
    "                                                    batch_size=12, \n",
    "                                                    pad_size=512, \n",
    "                                                    device= torch.device('cuda' if torch.cuda.is_available() else 'cpu'), \n",
    "                                                    add_title=False)\n",
    "roberta = RobertaModel.from_pretrained(roberta_path)\n",
    "roberta.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "for x in loader_embed:\n",
    "    y = x\n",
    "    with torch.no_grad():\n",
    "        embeddings = roberta( **x[0] ).pooler_output\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta地址 were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[    0,   787,   295,  ...,     1,     1,     1],\n",
       "         [    0,  5179,   139,  ...,     1,     1,     1],\n",
       "         [    0,   787,  8978,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0,  4070,   122,  ...,     1,     1,     1],\n",
       "         [    0, 15183,  4832,  ...,     1,     1,     1],\n",
       "         [    0,   118,    56,  ...,     1,     1,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')},\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0], device='cuda:0'),\n",
       " [\" @ n1ghtw1ng ( gosh i'm replying to you a lot this morning ! ) can i just say i'm glad i'm not the only one who says 'you' when i'm trying to comfort/pep talk myself. i could relate to some of your thoughts on gift giving and sitting alone in restaurants - your positives helped me see those things a little differently too , so thanks ! smiley happy hope you got the sleep you needed too. negative: dad 's home this morning while mum 's still at work. i'm really stressed out because i do n't want to be stuck dealing with him until class at 11am - that 's 3.5 hours ! positive: i can go into uni early , which will allow me to get some study done as well as distance myself from family. win-win. plus dad will be at work when i get home so it 's only this morning that i need to deal with him. i 've had to face this situation before and have survived - there 's no reason why this time should be any different. negative: this assignment is stressing me out so much because i'm procrastinating it. i'm used to starting my assignments early so this does n't happen. i just do n't want to do it. positive: it 's my last assignment for this semester. once it 's done that 'll be it ! the reason i'm delaying working on it is because i'm waiting to get a previous assignment back - the feedback from it will help me complete this new task. i should have my marks back by tomorrow which will give me the weekend + monday to do it. it 's only 1500 words so it should n't take too long.\",\n",
       "  ' hallo @ kyliesmiley99 and welcome to ro ! ',\n",
       "  \" @ orangeoliver i often procrastinate because i ca n't work up the mental and\\\\or physical energy to do whatever i planned. or , i pause for a couple of minutes and then loose track of time , get distracted. or i 've lost focus and my motivation is gone. what i'm working on is a number of projects. before it was a presentation for a meeting but i also have a book i 've been working on and another number of short ( or not so short ) stories with this program zen writer.\",\n",
       "  \"birdeye: oh my gosh. i swear every week since i 've been back i 've meant to join gr , and then both this and last week ( possibly the one before too but i do n't remember ) i 've come on just after 10pm then realised. haha , oh well. i will get there someday ! \",\n",
       "  \"hey @ j95 in my experience one of the best ways to be a role model for younger siblings is by trying your best in your own life. this does n't mean not making any mistakes , but constantly trying and finding a way to get by despite anything you 've done. most of my older siblings have at some point either completely backflipped on life or gotten onto a completely wrong track , but i'm inspired by the way they turn themselves around and into something that will make them happy. my best friend sees his older brother as a role model largely for a similar reason - his brother seems successful and most importantly happy. another really big aspect of seeing siblings as role models is them feeling like they 're on your side or are a friend. the easiest way to do this is probably to take interest in them. so ask him about whatever you know is going on in his life and get involved if you can. watch a show with him so that it feels like that 's the show that belongs to the two of you , or introduce him to some of your favourite bands. for me and my friends , whenever our older siblings have shared that sort of stuff with us it immediately become somewhat special. there 's one last one and it fits in really well to the above two: help him. offer to help him with his school work or find a tutor. help him learn about taking care of himself , for me one way one of my sisters did this that was wonderful was by always making me do a lot of the cooking when i was with her. the headspace idea goes into this really well. doing any of these things would be wonderful. that you want to help him out and that he does come to you already means that you 're doing something right.\",\n",
       "  \" why three ? xd + today my eyes felt baggy and dry and after i exercised after school , it 's gone ! + my maths teacher let me sleep in class because my eyes were hurting + took selfies with my friend , it felt good taking goofy photos during free session \",\n",
       "  \" @ j95 money spent in officeworks is money well spent ! @ redhead wishing you all the best. you are awesome. right now i am sleeping , there is a pimple on my shoulder making me want to cry and i just realised that i'm not sleeping , i am tired. but that goes to show that i am tired. but bed can wait for a few more hours i think.\",\n",
       "  \" @ sophie -ro the day and nights we play are pretty muddled up , some friday nights , some saturday 's , some sunday 's and some saturday nights. it 's a bit of a round robin sort of thing , this weekend is the second last. but this weekend is my last in the team because i'm going away.\",\n",
       "  \"thanks @ myvo @ lanejane i'm away at the moment so i'm using to sort of think about what and how i'm going to help him , while keeping my wellbeing in mind of course. it 's a bit stressful because he almost relies on me for everything and even thinks that if he tells me about failing school subjects or whatever , that i wo n't care and it 'll be fine... but it 's totally not and not ok to show up to my house when i'm not even home and help himself to using my stuff. i understand everything is sort of messed up for him at home and stuff but he 's going to get himself into so much trouble if he keeps doing what he is doing. i do n't want to be that person that ecourages it or says it ok , i'm 5 years older than him and feel pretty much responsible for him so i have to do something... i never had anyone when i was that age , i just figured out what was ok and what was n't , but some people do n't pick it up themselves.\",\n",
       "  \"right now i am sad because i am ill , happy because it means i can join gr today ! ( usually i ca n't ) and soon to start continuing my rewatch of rescue bots. yes , it 's a toddler show. no , i do n't care. smiley happy\",\n",
       "  \" neg : feeling rather demotivated and flat today. i do n't have the energy for anything. i 've strugled to interpret a couple obs. blergh pos : i 've gotten a couple obs interpreted ! go me ! i had a bit of a rough night 's sleep last night , so not surprised i'm a bit flat today. tmorrow could be better neg : found out where i'm going for prac , but it 's not where i wanted. pos : i know the centre. i 've been there before. i'm right next to the high school i attended 2 years ago ! neg : feeling myself starting to go down a path of self-loathing. the worst part being i do n't feel strong enough to combatt it today. nor do i have the energy or motivation to do so. ) : pos : i 've noticed this.i can get trough. i can use some distraction techniques to get through - music , movies , games , try to get this last ob interpreted and sent. finish painting my door hanger. continue researching a new head unit for my car \",\n",
       "  \"i had to come up with something like this when i was in therapy. i also filled a box with self-care stuff in it and it sits by my bed - highly recommend it ! some of the things in lokifish 's kit: - have a warm bubble bath - go for a walk - journaling - come on ro - watch the birds/trees/insects outside - books to read - teddies to cuddle with - mindfulness meditations/breathing exercises - chocolate - bubbles - colouring books - photos of happy places/events - moisturiser ( i like the feel of it on my hands ) - classical music to calm me down\"])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[    0, 24810, 29965,  ...,     1,     1,     1],\n",
       "         [    0,  4070,   122,  ...,     1,     1,     1],\n",
       "         [    0,   605, 42557,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    0, 17232, 19417,  ...,     1,     1,     1],\n",
       "         [    0, 17232, 27785,  ...,     1,     1,     1],\n",
       "         [    0,  2050,  3628,  ...,     1,     1,     1]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')},\n",
       " tensor([0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
